{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:38:10.524101Z",
     "iopub.status.busy": "2022-06-28T02:38:10.523850Z",
     "iopub.status.idle": "2022-06-28T02:38:14.346200Z",
     "shell.execute_reply": "2022-06-28T02:38:14.345492Z",
     "shell.execute_reply.started": "2022-06-28T02:38:10.524077Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dynet] random seed: 1234\n",
      "[dynet] allocating memory: 32MB\n",
      "[dynet] memory allocation done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # 读取文件\r\n",
    "import numpy as np # 数值计算\r\n",
    "import nagisa # 日文分词\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # 文本特征提取\r\n",
    "from sklearn.linear_model import LogisticRegression # 逻辑回归\r\n",
    "from sklearn.pipeline import make_pipeline # 组合流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:19:35.741941Z",
     "iopub.status.busy": "2022-06-28T02:19:35.741382Z",
     "iopub.status.idle": "2022-06-28T02:19:36.121595Z",
     "shell.execute_reply": "2022-06-28T02:19:36.120753Z",
     "shell.execute_reply.started": "2022-06-28T02:19:35.741898Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "train_cn = pd.read_excel('data/汽车领域多语种迁移学习挑战赛初赛训练集/中文_trian.xlsx')\r\n",
    "train_ja = pd.read_excel('data/汽车领域多语种迁移学习挑战赛初赛训练集/日语_train.xlsx')\r\n",
    "train_en = pd.read_excel('data/汽车领域多语种迁移学习挑战赛初赛训练集/英文_train.xlsx')\r\n",
    "test_ja = pd.read_excel('data/testA.xlsx', sheet_name='日语_testA')\r\n",
    "test_en = pd.read_excel('data/testA.xlsx', sheet_name='英文_testA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:23:39.043614Z",
     "iopub.status.busy": "2022-06-28T02:23:39.042633Z",
     "iopub.status.idle": "2022-06-28T02:23:39.049634Z",
     "shell.execute_reply": "2022-06-28T02:23:39.048859Z",
     "shell.execute_reply.started": "2022-06-28T02:23:39.043575Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['原始文本', '中文翻译', '意图', '槽值1', '槽值2'], dtype='object')\n",
      "原始文本 : <class 'str'>\n",
      "中文翻译 : <class 'str'>\n",
      "意图 : <class 'str'>\n",
      "槽值1 : <class 'float'>\n",
      "槽值2 : <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# 查看每列字段类型\r\n",
    "train_obj = train_en.columns\r\n",
    "print(train_obj)\r\n",
    "for col in train_obj:\r\n",
    "    print(col+' : '+str(type(train_en[col][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:22:49.455439Z",
     "iopub.status.busy": "2022-06-28T02:22:49.455107Z",
     "iopub.status.idle": "2022-06-28T02:22:49.461890Z",
     "shell.execute_reply": "2022-06-28T02:22:49.461037Z",
     "shell.execute_reply.started": "2022-06-28T02:22:49.455408Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['原始文本'], dtype='object')\n",
      "原始文本 : <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 查看每列字段类型\r\n",
    "test_obj = test_en.columns\r\n",
    "print(test_obj)\r\n",
    "for col in test_obj:\r\n",
    "    print(col+' : '+str(type(test_en[col][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:33:55.516655Z",
     "iopub.status.busy": "2022-06-28T02:33:55.516191Z",
     "iopub.status.idle": "2022-06-28T02:33:56.946829Z",
     "shell.execute_reply": "2022-06-28T02:33:56.946029Z",
     "shell.execute_reply.started": "2022-06-28T02:33:55.516605Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.869 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['阿水', '是', '一个', '好', '同志', '。']\n"
     ]
    }
   ],
   "source": [
    "import jieba\r\n",
    "import jieba.posseg as pseg\r\n",
    "\r\n",
    "words = jieba.lcut(\"阿水是一个好同志。\")\r\n",
    "print(words)\r\n",
    "# ['阿水', '是', '一个', '好', '同志', '。']\r\n",
    "\r\n",
    "words = pseg.lcut(\"阿水是一个好同志。\")\r\n",
    "# [pair('阿水', 'nr'), pair('是', 'v'), pair('一个', 'm'), pair('好', 'a'), pair('同志', 'n'), pair('。', 'x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:39:49.288237Z",
     "iopub.status.busy": "2022-06-28T02:39:49.287719Z",
     "iopub.status.idle": "2022-06-28T02:39:51.838655Z",
     "shell.execute_reply": "2022-06-28T02:39:51.837744Z",
     "shell.execute_reply.started": "2022-06-28T02:39:49.288187Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 文本分词\r\n",
    "train_ja['words'] = train_ja['原始文本'].apply(lambda x: ' '.join(nagisa.tagging(x).words))\r\n",
    "train_en['words'] = train_en['原始文本'].apply(lambda x: x.lower())\r\n",
    "\r\n",
    "test_ja['words'] = test_ja['原始文本'].apply(lambda x: ' '.join(nagisa.tagging(x).words))\r\n",
    "test_en['words'] = test_en['原始文本'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:39:55.472781Z",
     "iopub.status.busy": "2022-06-28T02:39:55.472276Z",
     "iopub.status.idle": "2022-06-28T02:42:31.075142Z",
     "shell.execute_reply": "2022-06-28T02:42:30.984624Z",
     "shell.execute_reply.started": "2022-06-28T02:39:55.472747Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练TFIDF和逻辑回归\r\n",
    "pipline = make_pipeline(\r\n",
    "    TfidfVectorizer(),\r\n",
    "    LogisticRegression()\r\n",
    ")\r\n",
    "pipline.fit(\r\n",
    "    train_ja['words'].tolist() + train_en['words'].tolist(),\r\n",
    "    train_ja['意图'].tolist() + train_en['意图'].tolist()\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T02:56:17.611703Z",
     "iopub.status.busy": "2022-06-28T02:56:17.610920Z",
     "iopub.status.idle": "2022-06-28T02:56:18.000049Z",
     "shell.execute_reply": "2022-06-28T02:56:17.998995Z",
     "shell.execute_reply.started": "2022-06-28T02:56:17.611668Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型预测\r\n",
    "test_ja['意图'] = pipline.predict(test_ja['words'])\r\n",
    "test_en['意图'] = pipline.predict(test_en['words'])\r\n",
    "test_en['槽值1'] = np.nan\r\n",
    "test_en['槽值2'] = np.nan\r\n",
    "\r\n",
    "test_ja['槽值1'] = np.nan\r\n",
    "test_ja['槽值2'] = np.nan\r\n",
    "\r\n",
    "# 写入提交文件\r\n",
    "writer = pd.ExcelWriter('submit.xlsx')\r\n",
    "test_en.drop(['words'], axis=1).to_excel(writer, sheet_name='英文_testA', index=None)\r\n",
    "test_ja.drop(['words'], axis=1).to_excel(writer, sheet_name='日语_testA', index=None)\r\n",
    "writer.save()\r\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
